{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f5a4fab-f258-4009-aa03-49292e6ecdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_0                                                         34\n",
       "index                                                          393\n",
       "ID                                                             393\n",
       "Country                                                     russia\n",
       "Background       ### Visiting\\n- When visiting a Russian home, ...\n",
       "Axis                                                     Etiquette\n",
       "Subaxis                                                   visiting\n",
       "Value                 Hospitality and reciprocity in interactions.\n",
       "Rule-of-Thumb    It is respectful to bring gifts when visiting ...\n",
       "Explanation      Bringing a gift when visiting someone's home a...\n",
       "Gold Label                                                     yes\n",
       "Story            Emily went to visit Mark's house for the first...\n",
       "social_action    Emily brought a bottle of wine and some chocol...\n",
       "new_stories      What would be Emily's appropriate actions as s...\n",
       "revised_story    What would be Emily's appropriate actions as s...\n",
       "Name: 34, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Step 1: Load environment variables from .env file\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "# Step 2: Retrieve Azure OpenAI environment variables\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "OPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "\n",
    "# Step 3: Initialize the Azure OpenAI model with required parameters\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-4o-mini\",  # Your Azure deployment\n",
    "    api_version=OPENAI_API_VERSION,  # Your API version\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    temperature=0,  # Controls randomness; 0 is more deterministic\n",
    "    max_tokens=60,  # Set according to your needs\n",
    "    timeout=None  # Adjust if needed\n",
    ")\n",
    "\n",
    "model_35 = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-35-turbo\",  # Your Azure deployment\n",
    "    api_version=OPENAI_API_VERSION,  # Your API version\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    temperature=0,  # Controls randomness; 0 is more deterministic\n",
    "    max_tokens=60,  # Set according to your needs\n",
    "    timeout=None  # Adjust if needed\n",
    ")\n",
    "\n",
    "model_llama3 = ChatGroq(\n",
    "    model=\"llama-3.3-70b-specdec\",\n",
    "    temperature=0,\n",
    "    max_tokens=60,\n",
    "    timeout=None,\n",
    "    # max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"random_samples_new_revised.csv\")\n",
    "# print(df.head())\n",
    "\n",
    "import numpy as np\n",
    "# Use iloc to select the row by index\n",
    "samples = df[df[\"Gold Label\"]==\"yes\"].reset_index() \n",
    "random_index = np.random.choice(samples.index)\n",
    "random_samples = samples.iloc[random_index]\n",
    "random_samples\n",
    "\n",
    "# Generate 100 random indices from a range of 0 to 1000 (exclusive)\n",
    "# random_indices = np.random.randint(0, len(samples), size=100)\n",
    "\n",
    "# print(random_indices)\n",
    "\n",
    "# random_samples = samples.iloc[random_indices]\n",
    "# random_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f23e5f4b-0bf3-4e6f-9374-6d14e224abb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================  Revised Story  ====================\n",
      "What would be Emily's appropriate actions as she visited Mark's house for the first time?\n",
      "====================  Action  ====================\n",
      "In Russia, when visiting someone's home for the first time, it's customary to bring a gift, such as flowers, chocolates, or a bottle of wine. Emily should also remove her shoes before entering, as many Russian homes have a no-shoes policy. Additionally, she should greet Mark with\n",
      "====================  Explanation  ====================\n",
      "Bringing a gift when visiting someone's home and offering to help clean after meals are seen as respectful gestures. Emily's actions are socially acceptable given the cultural context.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create a NormBank prompt template for generating dialogue\n",
    "action_template = \"\"\"\n",
    "You are a cultural expert. There is a question to consider:\n",
    "\n",
    "Story: \n",
    "{question}\n",
    "\n",
    "Action: Provide a brief, culturally-informed response to the question based on {country}. Make it concise.\n",
    "\"\"\"\n",
    "\n",
    "action_prompt = PromptTemplate(\n",
    "    template=action_template,\n",
    "    input_variables=[\"question\", \"country\"]\n",
    ")\n",
    "\n",
    "# Step 6: Define output parser (just as you have done in the reference)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Step 7: Chain the components together (prompt + model + output parser)\n",
    "action_chain = action_prompt | model_llama3 | output_parser\n",
    "\n",
    "# Step 8: Define input values and invoke the chain to generate the dialogue\n",
    "input_values = {\n",
    "    \"question\" : random_samples['revised_story'],\n",
    "    \"country\" : random_samples['Country']\n",
    "}\n",
    "\n",
    "# Step 9: Generate the result\n",
    "action = action_chain.invoke(input_values)\n",
    "print(\"=\"*20, \" Revised Story \", \"=\"*20)\n",
    "print(random_samples[\"revised_story\"])\n",
    "print(\"=\"*20, \" Action \", \"=\"*20)\n",
    "print(action)\n",
    "print(\"=\"*20, \" Explanation \", \"=\"*20)\n",
    "print(random_samples[\"Explanation\"])\n",
    "\n",
    "\n",
    "# 348\n",
    "# ==================================================\n",
    "# In Germany, as Sarah arrives at the caf√© to meet her friends, an appropriate action would be to greet them with a handshake or a kiss on each cheek (depending on the level of familiarity), and say \"Hallo\" or \"Guten Tag\" (hello or good day). It's also customary\n",
    "# ==================================================\n",
    "# Given the cultural context, Sarah's actions demonstrate respect for punctuality, personal space, and social etiquette, making her actions socially acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2aeb84a8-7bd6-4580-9bcf-73c2bce638b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entail_template = \"\"\"\n",
    "# Classify the Textual entailment of given ground truth and action, answer only \"entailment\" or \"contradiction\"\n",
    "\n",
    "# Response Format:\n",
    "# Social Action : social action of response\n",
    "# Entailment: entailment/contradiction\n",
    "# Reasoning: rational information\\\n",
    "\n",
    "# Explanation: {explanation}\n",
    "# Acton : {action}\n",
    "# Output:\n",
    "# \"\"\"\n",
    "\n",
    "# entail_prompt = PromptTemplate(\n",
    "#     template=entail_template,\n",
    "#     input_variables=[\"ground_truth\", \"action\"]\n",
    "# )\n",
    "\n",
    "# # Step 6: Define output parser (just as you have done in the reference)\n",
    "# output_parser = StrOutputParser()\n",
    "\n",
    "# # Step 7: Chain the components together (prompt + model + output parser)\n",
    "# entail_chain = entail_prompt | model | output_parser\n",
    "\n",
    "# # Step 8: Define input values and invoke the chain to generate the dialogue\n",
    "# input_values = {\n",
    "#     \"explanation\" : sample['Explanation'],\n",
    "#     \"action\" : action\n",
    "# }\n",
    "\n",
    "# # Step 9: Generate the result\n",
    "# text_entailment = entail_chain.invoke(input_values)\n",
    "# print(text_entailment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "380b65d4-89e0-461e-8180-b9130e7b46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accept_template = \"\"\"\n",
    "# {story}\n",
    "# Answer only `yes`, `no` or `neutral`\n",
    "# \"\"\"\n",
    "\n",
    "# accept_prompt = PromptTemplate(\n",
    "#     template=accept_template,\n",
    "#     input_variables=[\"story\"]\n",
    "# )\n",
    "\n",
    "# # Step 6: Define output parser (just as you have done in the reference)\n",
    "# output_parser = StrOutputParser()\n",
    "\n",
    "# # Step 7: Chain the components together (prompt + model + output parser)\n",
    "# accept_chain = accept_prompt | model | output_parser\n",
    "\n",
    "# # Step 8: Define input values and invoke the chain to generate the dialogue\n",
    "# input_values = {\n",
    "#     \"story\" : sample['Story'],\n",
    "# }\n",
    "\n",
    "# # Step 9: Generate the result\n",
    "# acceptablility = accept_chain.invoke(input_values)\n",
    "# acceptablility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ce5dd0d-3124-4107-bd99-86b062c6677b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(f\"\"\" \n",
    "# Story: \n",
    "# {sample[\"Story\"]}\n",
    "# Country: \n",
    "# {sample['Country']}\n",
    "# Label:\n",
    "# {sample['Gold Label']}\n",
    "# --------------------------------------------------------\n",
    "# Question: \n",
    "# {questions}\n",
    "# --------------------------------------------------------\n",
    "# Explanation:\n",
    "# {sample['Explanation']}\n",
    "\n",
    "# Action:\n",
    "# {action}\n",
    "# ------------------------------------------------\n",
    "# NLI :\n",
    "# {text_entailment}\n",
    "# Acceptable : {acceptablility}\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697a302e-df96-46b4-b7d2-ff8a8a6a3a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv thainorms)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
